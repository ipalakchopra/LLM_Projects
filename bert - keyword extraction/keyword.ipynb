{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "        Good evening sir, apologies for the late message but just received your email regarding the cancellation of tomorrow's meeting.\n",
    "Following are our updates:\n",
    "1. Ishnoor has written a comparison between Kibana and Grafana based on her exploration of the 2 tools. So far, we have been more successful in replicating Saee's design in Kibana, and also writing the rules due the compatibility in the ELK stack. We wanted to discuss these with you and decide which tool to pursue further, as of now. \n",
    "2. Sanket has enabled NAS storage on his CPU to store a backup of our proxmox cluster outside of the 3 nodes. Working on adding a job to push this to github as well. He has an idea to optimise Logstash's role using Python, the way he had done with SMTP, which we wanted to discuss with you before pursuing it further.\n",
    "3. Omkar is working on setting up Modsecurity as a reverse proxy for our web, mail and keycloak server.\n",
    "4. All of us have started writing use cases on firewall. We're maintaining a sheet called Rule_List. Currently we have limited use case but we'll pick up today onwards as some of our other tasks just got over.\n",
    "5. Aaditya has worked on further hardening Kafka and Logstash. There was a power cut on Tuesday so it got unintentionally tested and luckily, it survived. He's also doing further reading on the Misinformation project.\n",
    "6. I have started working on deployment and have planned out 2 approaches: Docker Compose for single server and Ansible for individual. This is a longer task but I have started with the Docker approach and have uploaded a small documentation for reference.\n",
    "7. Saee has a proposal for a paper in a design conference in IIT Delhi that we also want to discuss. (She has added the details in the sheet)\n",
    "As for this week's Threat Intel, we are still updating the documents.\"\"\"\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logstash', 0.564),\n",
       " ('kibana', 0.4733),\n",
       " ('nas', 0.3197),\n",
       " ('modsecurity', 0.3026),\n",
       " ('elk', 0.2937)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
